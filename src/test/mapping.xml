<?xml version="1.0"?>
<network inputs="2">
    <layers>
        <layer neurons="2"/>
        <layer neurons="3"/>
        <layer neurons="2"/>
    </layers>

    <settings activation-function="Sigmoid" cost-function="CrossEntropy">
        <training learning="BackPropagation" iterations="10000" error="0.01">
            <dropout activate="false" factor="0.5"/>
            <method>
                <!--backprop learning-rate="1.2"/-->
                <rprop>
                    <eta   positive="1.2" negative="0.95"/>
                    <delta min="0.000001" max="50.0"/>
                </rprop>
            </method>
        </training>
    </settings>
</network>
